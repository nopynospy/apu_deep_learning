{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgQ2/ZIWSQQVY9/0UZjxY/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak-0a9Alvvh4"
      },
      "source": [
        "# LAB 3-Online_shopper_Call backs_cm_Regularization_Optimization\n",
        "\n",
        "## Objectives of the LAB:\n",
        "1. Introduce a variety of call backs, plotting, file and history saving, viewing weights of layers and performance metrics.\n",
        "2. Perform regularization and Batch normalization.\n",
        "3. Evaluate performace of the models.\n",
        "4. Compare performance of the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYAvdOT8v8MF"
      },
      "source": [
        "## 1. Importing Libraries and mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlexlzUwtF2S"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow import keras\n",
        "from keras import utils as np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ymtCWNzw6Bt"
      },
      "source": [
        "# 2. Loading and Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf0jEwKIw765"
      },
      "source": [
        "train_df = pd.read_csv('https://raw.githubusercontent.com/nopynospy/apu_deep_learning/main/online%20shop_train.csv')\n",
        "test_df = pd.read_csv('https://raw.githubusercontent.com/nopynospy/apu_deep_learning/main/online%20shop_test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x8NPHMXxSsP",
        "outputId": "5fc54f71-aeab-4fd4-8f9c-10b78fb41f54"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16626, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ1tMO2sxUIt",
        "outputId": "1e7c7db0-cdfa-4fde-9b38-19becf0f62d0"
      },
      "source": [
        "test_df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2466, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TifJ7ZZrxYf9"
      },
      "source": [
        "# Split dataset to independent (X) and target (y) variables\n",
        "X_train = train_df.iloc[:,:-1]\n",
        "y_train = train_df.iloc[:,-1]\n",
        "X_test = test_df.iloc[:,:-1]\n",
        "y_test = test_df.iloc[:,-1]\n",
        "# One-hot encoding the target variables from the training, validation and test datasets for classification\n",
        "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=None, dtype=\"int\")\n",
        "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=None, dtype=\"int\")\n",
        "# Clearing the nodes left behind in the previous session to free up memory and preventing slowdown.\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZoGguA5xu9s"
      },
      "source": [
        "# 4. Misc features\n",
        "## 4.1 Layer Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv21MfM6ym6F",
        "outputId": "578f3fb9-c51f-4e04-e688-91f3edadb218"
      },
      "source": [
        "def create_baseline():\n",
        "    #Initializing Neural Network\n",
        "    classifier = Sequential()\n",
        "\n",
        "    ##Defining the architecture of ANN\n",
        "   \n",
        "    # First layer \n",
        "    classifier.add(Dense(units = 512, kernel_initializer = 'he_uniform', activation = 'relu', input_dim = 12))\n",
        "    \n",
        "    # Second layer\n",
        "    classifier.add(Dense(units= 128 , kernel_initializer = 'he_uniform', activation = 'relu'))\n",
        "    \n",
        "    classifier.add(Dense(units= 96, kernel_initializer = 'he_uniform', activation = 'relu'))\n",
        "    # Adding the output layer\n",
        "    classifier.add(Dense(units = 2, kernel_initializer = 'he_uniform', activation = 'softmax'))\n",
        "    \n",
        "   \n",
        "    # Compiling Neural Network\n",
        "    ## specifying optimizer \n",
        "    ## This is the metaparameter, specfiying the metaparameter , (adam is popular optimizer like SGD, and GD, \n",
        "    ## the binary_corssentropy is because it has 2 class)\n",
        "    \n",
        "    \n",
        "    # classifier.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    classifier.compile(optimizer = 'SGD', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "model_baseline = create_baseline()\n",
        "print(model_baseline.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               6656      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 96)                12384     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 194       \n",
            "=================================================================\n",
            "Total params: 84,898\n",
            "Trainable params: 84,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo1A3wLoyt4V",
        "outputId": "c854d4db-5673-41ce-bd34-928bec208b91"
      },
      "source": [
        "hidden1 = model_baseline.layers[1]\n",
        "weights, biases = hidden1.get_weights()\n",
        "weights"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04067964, -0.00336043,  0.09331302, ...,  0.00245792,\n",
              "         0.09733552, -0.08533823],\n",
              "       [ 0.06069423,  0.09338554,  0.09013639, ..., -0.05562919,\n",
              "        -0.09915592, -0.07003643],\n",
              "       [-0.03871035,  0.06407639, -0.04704274, ...,  0.08028995,\n",
              "        -0.03738622,  0.0967179 ],\n",
              "       ...,\n",
              "       [-0.09992407,  0.05533648,  0.05717779, ...,  0.03523437,\n",
              "        -0.00272727, -0.05270342],\n",
              "       [-0.07520302, -0.04225121, -0.03619627, ..., -0.06922771,\n",
              "        -0.03622319, -0.00147122],\n",
              "       [-0.03755522, -0.06533077, -0.0409788 , ...,  0.05789558,\n",
              "        -0.04246469,  0.01773887]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5M64sdD1LTU"
      },
      "source": [
        "Save the entire model to a HDF5 file.\n",
        "\n",
        "The '.h5' extension indicates that the model should be saved to HDF5.\n",
        "\n",
        "(In this case, to not be only limited to Google Colab and drive, I downloaded it)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kjLi2oCFzhV_",
        "outputId": "98c9a254-29e2-4729-c9ce-ac5b713d8f1b"
      },
      "source": [
        "model_baseline.save('lab3_baseline.h5')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('lab3_baseline.h5')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_adc86cbd-6528-48de-b768-2b32f5ccbb32\", \"lab3_baseline.h5\", 358160)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKcJNK9M1bCM"
      },
      "source": [
        "## 4.3 Restoring saved model and history\n",
        "\n",
        "(Behind the scenes, I uploaded the downloaded h5 file to my GitHub)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng8xJOAZ2uVd",
        "outputId": "f67f2cd9-4c8c-41e4-e56c-4bfd13d44141"
      },
      "source": [
        "!git clone https://github.com/nopynospy/apu_deep_learning.git"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'apu_deep_learning'...\n",
            "remote: Enumerating objects: 65, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 65 (delta 27), reused 25 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (65/65), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHHiGHf33BtE",
        "outputId": "deea2cfd-03b5-4bb8-9357-002073999f56"
      },
      "source": [
        "!cd apu_deep_learning/\n",
        "!ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apu_deep_learning  lab3_baseline.h5  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCEEe0An1EwF"
      },
      "source": [
        "model = keras.models.load_model('lab3_baseline.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}